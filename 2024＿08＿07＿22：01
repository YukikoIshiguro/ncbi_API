import requests
import os
import pandas as pd
from datetime import datetime
from xml.etree import ElementTree as ET

def format_date(date_str):
    for fmt in ("%Y/%m/%d", "%Y年%m月%d日", "%Y年%m月", "%Y年"):
        try:
            return datetime.strptime(date_str, fmt).strftime("%Y/%m/%d")
        except ValueError:
            continue
    return date_str

def fetch_pubmed_data(journal=None, pdat=None, volume=None, issue=None, authors=None):
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    db = "pubmed"
    retmode = "json"

    params = {
        "db": db,
        "retmode": retmode,
        "term": f"{journal}[journal]" if journal else None,
        "mindate": pdat,
        "maxdate": pdat,
        "volume": volume,
        "issue": issue,
        "author": authors
    }

    filtered_params = {key: value for key, value in params.items() if value}
    response = requests.get(base_url, params=filtered_params)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Error: {response.status_code}")
        print(response.text)
        return {"error": f"Failed to fetch data, status code: {response.status_code}", "details": response.text}

def fetch_article_details(uid):
    base_url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    db = "pubmed"
    retmode = "xml"

    params = {
        "db": db,
        "retmode": retmode,
        "id": uid
    }

    response = requests.get(base_url, params=params)
    if response.status_code == 200:
        return response.text
    else:
        print(f"Error fetching article {uid}: {response.status_code}")
        return None

def parse_article_details(xml_data):
    root = ET.fromstring(xml_data)
    title = root.findtext(".//ArticleTitle")
    link = f"https://pubmed.ncbi.nlm.nih.gov/{title}/?term=Barcoding%20of%20episodic%20memories%20in%20the%20hippocampus%20of%20a%20food-caching%20bird./"
    
    return title, link

def fetch_citmatch_data(journal, volume, page):
    url = f"https://pubmed.ncbi.nlm.nih.gov/api/citmatch/?method=field&journal={journal}&volume={volume}&page={page}"
    response = requests.get(url)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Error: {response.status_code}")
        print(response.text)
        return {"error": f"Failed to fetch data, status code: {response.status_code}", "details": response.text}

def main():
    print("PubMed Search")
    journal = input("Enter journal name (or leave blank): ")
    pdat = input("Enter publication date (YYYY/MM/DD, YYYY年MM月DD日, etc., or leave blank): ")
    volume = input("Enter volume (or leave blank): ")
    issue = input("Enter issue (or leave blank): ")
    authors = input("Enter authors (format: Surname Initial, or leave blank): ")

    if not (journal or pdat or volume or issue or authors):
        print("Error: At least one search parameter must be provided.")
        return

    result = fetch_pubmed_data(journal, pdat, volume, issue, authors)
    
    if "error" in result:
        print(result)
        return
    
    titles = []
    links = []
    if "esearchresult" in result and "idlist" in result["esearchresult"]:
        for uid in result["esearchresult"]["idlist"]:
            details = fetch_article_details(uid)
            if details:
                title, link = parse_article_details(details)
                titles.append(title)
                links.append(link)
    
    # Fetch additional data using citmatch API
    citmatch_result = fetch_citmatch_data("Front Immunol", "13", "826091")
    if "result" in citmatch_result and "uids" in citmatch_result["result"]:
        for item in citmatch_result["result"]["uids"]:
            uid = item["pubmed"]
            details = fetch_article_details(uid)
            if details:
                title, link = parse_article_details(details)
                titles.append(title)
                links.append(link)
    
    data = {
        'Title': titles,
        'Link': links
    }

    df = pd.DataFrame(data)

    output_directory = os.path.join(os.path.expanduser('~'), 'Documents')
    output_file_path = os.path.join(output_directory, 'ncbi_result_info.xlsx')

    df.to_excel(output_file_path, index=False, engine='openpyxl')

    print(f"Excelファイル '{output_file_path}' に保存されたよ！")

if __name__ == "__main__":
    main()
