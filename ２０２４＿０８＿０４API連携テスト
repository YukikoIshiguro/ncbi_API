import requests
import os
import pandas as pd
from xml.etree import ElementTree as ET

def generate_citmatch_link(journal, volume, page, year=None):
    base_url = "https://pubmed.ncbi.nlm.nih.gov/api/citmatch/?method=field"
    link = f"{base_url}&journal={journal}&volume={volume}&page={page}"
    if year:
        link += f"&year={year}"
    return link

def fetch_pubmed_data(link):
    response = requests.get(link)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Error: {response.status_code}")
        print(response.text)
        return {"error": f"Failed to fetch data, status code: {response.status_code}", "details": response.text}

def fetch_article_details(uid):
    """Fetch article details from PubMed given a UID."""
    base_url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    params = {
        "db": "pubmed",
        "retmode": "xml",
        "id": uid
    }
    response = requests.get(base_url, params=params)
    if response.status_code == 200:
        return response.text
    else:
        print(f"Error fetching article {uid}: {response.status_code}")
        return None

def parse_article_details(xml_data):
    """Parse the XML data to extract relevant article details."""
    root = ET.fromstring(xml_data)
    title = root.findtext(".//ArticleTitle")
    link = f"https://pubmed.ncbi.nlm.nih.gov/{title}/"
    return title, link

def main():
    print("PubMed Search")
    journal = input("Enter journal name: ")
    volume = input("Enter volume: ")
    page = input("Enter page number: ")
    year = input("Enter year (optional): ")

    # リンクの文字列を生成
    citmatch_link = generate_citmatch_link(journal, volume, page, year)
    print(f"Generated link: {citmatch_link}")

    # PubMedデータを取得
    result = fetch_pubmed_data(citmatch_link)
    if "error" in result:
        print(f"Error: {result['error']}")
        print(f"Details: {result['details']}")
        return

    print(f"Response: {result}")

    if result.get("result", {}).get("count", 0) == 0:
        print("No results found.")
        return

    titles = []
    links = []
    if "result" in result and "uids" in result["result"]:
        for uid_info in result["result"]["uids"]:
            uid = uid_info["pubmed"]
            details = fetch_article_details(uid)
            if details:
                title, link = parse_article_details(details)
                titles.append(title)
                links.append(link)
    
    # 解析したデータを辞書に保存
    data = {
        'Title': titles,
        'Link': links
    }

    # データフレームを作成
    df = pd.DataFrame(data)

    # 出力ファイルパスをユーザーのドキュメントフォルダに設定
    output_directory = os.path.join(os.path.expanduser('~'), 'Documents')
    output_file_path = os.path.join(output_directory, 'ncbi_result_info.xlsx')

    # データフレームをExcelファイルに書き出す
    df.to_excel(output_file_path, index=False, engine='openpyxl')

    print(f"Excelファイル '{output_file_path}' に保存されたよ！")

if __name__ == "__main__":
    main()
