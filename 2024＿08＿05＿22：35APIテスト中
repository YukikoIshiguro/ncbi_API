import requests
import os
import pandas as pd
from datetime import datetime
from xml.etree import ElementTree as ET

def format_date(date_str):
    """Try to parse different date formats and return a standardized date string."""
    for fmt in ("%Y/%m/%d", "%Y年%m月%d日", "%Y年%m月", "%Y年"):
        try:
            return datetime.strptime(date_str, fmt).strftime("%Y/%m/%d")
        except ValueError:
            continue
    return date_str  # Return the original string if no format matches

def fetch_pubmed_data(journal=None, volume=None, page=None, year=None, authors=None):
    base_url = "https://pubmed.ncbi.nlm.nih.gov/api/citmatch/"
    params = {
        "method": "field",
        "journal": journal.replace(" ", "%20") if journal else None,
        "volume": volume,
        "page": page,
        "authors": authors.replace(" ", "%20") if authors else None,
        "year": year
    }

    # Filter out empty parameters and construct the query string
    filtered_params = {key: value for key, value in params.items() if value}
    query_string = "&".join([f"{key}={value}" for key, value in filtered_params.items()])
    url = f"{base_url}?{query_string}"

    print(f"Requesting URL: {url}")  # Debug output

    response = requests.get(url)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Error: {response.status_code}")  # Debug output
        print(response.text)  # Debug output
        return {"error": f"Failed to fetch data, status code: {response.status_code}", "details": response.text}

def fetch_article_details(uid):
    """Fetch article details from PubMed given a UID."""
    base_url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    db = "pubmed"
    retmode = "xml"

    params = {
        "db": db,
        "retmode": retmode,
        "id": uid
    }

    response = requests.get(base_url, params=params)
    if response.status_code == 200:
        return response.text  # For simplicity, return the XML content
    else:
        print(f"Error fetching article {uid}: {response.status_code}")
        return None

def parse_article_details(xml_data):
    """Parse the XML data to extract relevant article details."""
    root = ET.fromstring(xml_data)
    title = root.findtext(".//ArticleTitle")
    pmid = root.findtext(".//PMID")
    link = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
    
    return title, link

def main():
    print("PubMed Search")
    journal = input("Enter journal name (or leave blank): ")
    volume = input("Enter volume (or leave blank): ")
    page = input("Enter page number (or leave blank): ")
    year = input("Enter publication year (or leave blank): ")
    authors = input("Enter authors (format: Surname Initial, or leave blank): ")

    # Ensure at least one parameter is provided
    if not (journal or volume or page or year or authors):
        print("Error: At least one search parameter must be provided.")
        return

    result = fetch_pubmed_data(journal, volume, page, year, authors)
    
    if "error" in result:
        print(result)
        return
    
    titles = []
    links = []
    if "result" in result and "uids" in result["result"]:
        for uid_info in result["result"]["uids"]:
            uid = uid_info["pubmed"]
            details = fetch_article_details(uid)
            if details:
                title, link = parse_article_details(details)
                titles.append(title)
                links.append(link)
    
    # 解析したデータを辞書に保存
    data = {
        'Title': titles,
        'Link': links
    }

    # データフレームを作成
    df = pd.DataFrame(data)

    # 出力ファイルパスをユーザーのドキュメントフォルダに設定
    output_directory = os.path.join(os.path.expanduser('~'), 'Documents')
    output_file_path = os.path.join(output_directory, 'ncbi_result_info.xlsx')

    # データフレームをExcelファイルに書き出す
    df.to_excel(output_file_path, index=False, engine='openpyxl')

    print(f"Excelファイル '{output_file_path}' に保存されたよ！")

if __name__ == "__main__":
    main()
